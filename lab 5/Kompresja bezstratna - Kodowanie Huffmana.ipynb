{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99600289-7337-4cf1-a507-50394641c392",
   "metadata": {},
   "source": [
    "# Kompresja bezstratna - Kodowanie Huffmana\n",
    "*Ivan Kaliadzich 153936*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6348117e-fc57-4158-ab7a-a7d4c0b39e03",
   "metadata": {},
   "source": [
    "## Dodawanie bibliotek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4208ce0-4456-4efc-8656-81777f7f4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bitarray\n",
    "import time\n",
    "import heapq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef91435-441f-4194-a361-e3369383ca71",
   "metadata": {},
   "source": [
    "## Alphabet i odczytanie pliku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13002ae2-a5e1-469a-9143-e867d608ea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', '1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
    "\n",
    "small_text = \"to be or not to be\"\n",
    "\n",
    "text_file = open(\"norm_wiki_sample.txt\", \"r\")\n",
    "data = text_file.read()\n",
    "text_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1d3c1e-9dc6-4dd6-b4b8-401193e47997",
   "metadata": {},
   "source": [
    "## Sprawdzenie działania dla małego tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9d42ed7-8097-4f24-94ad-88ca9563a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('n', 1), ('r', 1), ('b', 2), ('e', 2), ('t', 3), ('o', 4), (' ', 5)]\n",
      "[('b', 2), ('e', 2), ('{n,r}', 2), ('t', 3), ('o', 4), (' ', 5)]\n",
      "[('{n,r}', 2), ('t', 3), ('o', 4), ('{b,e}', 4), (' ', 5)]\n",
      "[('o', 4), ('{b,e}', 4), (' ', 5), ('{{n,r},t}', 5)]\n",
      "[(' ', 5), ('{{n,r},t}', 5), ('{o,{b,e}}', 8)]\n",
      "[('{o,{b,e}}', 8), ('{ ,{{n,r},t}}', 10)]\n",
      "Final combined key: {{o,{b,e}},{ ,{{n,r},t}}}\n"
     ]
    }
   ],
   "source": [
    "letter_count = {}\n",
    "\n",
    "for char in small_text:\n",
    "    if char in letter_count:\n",
    "        letter_count[char] += 1\n",
    "    else:\n",
    "        letter_count[char] = 1\n",
    "\n",
    "while len(letter_count)>1:\n",
    "    sorted_items = sorted(letter_count.items(), key=lambda item: (item[1], item[0])) \n",
    "    \n",
    "    smallest_1 = sorted_items[0]\n",
    "    smallest_2 = sorted_items[1]\n",
    "    del letter_count[smallest_1[0]]\n",
    "    del letter_count[smallest_2[0]]\n",
    "    \n",
    "    new_key = f'{{{smallest_1[0]},{smallest_2[0]}}}'\n",
    "    new_value = smallest_1[1] + smallest_2[1]\n",
    "    \n",
    "    letter_count[new_key] = new_value\n",
    "    \n",
    "    print(sorted_items) \n",
    "\n",
    "final_combined_key = list(letter_count.keys())[0]\n",
    "print(f\"Final combined key: {final_combined_key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536fbbd5-a4c7-40e8-88f2-9e6d60ce36be",
   "metadata": {},
   "source": [
    "## Sprawdzenie dla \"norm_wiki_sample.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c195bfac-fc5c-46ad-9dc5-49220b9d7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryTree:\n",
    "\n",
    "    def __init__(self, left_node, right_node):\n",
    "        self.left_node = left_node\n",
    "        self.right_node = right_node\n",
    "\n",
    "    def get_children(self):\n",
    "        return self.left_node, self.right_node\n",
    "\n",
    "\n",
    "def calculate_frequency(text, alphabet):\n",
    "    frequency_dict = dict.fromkeys(alphabet, 0)\n",
    "    for character in text:\n",
    "        frequency_dict[character] += 1\n",
    "    return sorted(frequency_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "\n",
    "def generate_codes(node, is_left=True, binary_string=''):\n",
    "    if type(node) is str:\n",
    "        return {node: binary_string}\n",
    "    left, right = node.get_children()\n",
    "    code_dict = {}\n",
    "    code_dict.update(generate_codes(left, True, binary_string + '0'))\n",
    "    code_dict.update(generate_codes(right, False, binary_string + '1'))\n",
    "    return code_dict\n",
    "\n",
    "\n",
    "def build_tree(text):\n",
    "    nodes = calculate_frequency(text, alphabet)\n",
    "\n",
    "    while len(nodes) > 1:\n",
    "        (char1, freq1) = nodes[-1]\n",
    "        (char2, freq2) = nodes[-2]\n",
    "        nodes = nodes[:-2]\n",
    "        new_node = BinaryTree(char1, char2)\n",
    "        nodes.append((new_node, freq1 + freq2))\n",
    "        nodes = sorted(nodes, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    huffman_codes = generate_codes(nodes[0][0])\n",
    "\n",
    "    return huffman_codes\n",
    "\n",
    "\n",
    "def decode_text(encoded_text, codes):\n",
    "    decoded_output = ''\n",
    "    reverse_codes = {v: k for k, v in codes.items()}\n",
    "    start_index = 0\n",
    "    for i in range(0, len(encoded_text) + 1):\n",
    "        if encoded_text[start_index:i] in reverse_codes:\n",
    "            decoded_output += reverse_codes[encoded_text[start_index:i]]\n",
    "            start_index = i\n",
    "    return decoded_output\n",
    "\n",
    "\n",
    "def encode_text(text, codes):\n",
    "    encoded_output = \"\"\n",
    "    for character in text:\n",
    "        encoded_output += codes[character]\n",
    "    return encoded_output\n",
    "\n",
    "\n",
    "def save_to_files(code_filename, codes, binary_filename, encoded_text):\n",
    "    with open(code_filename, 'w') as code_file:\n",
    "        for character, binary in codes.items():\n",
    "            code_file.write(character + \";\" + str(binary) + \";\")\n",
    "\n",
    "    bits = bitarray.bitarray(encoded_text)\n",
    "\n",
    "    with open(binary_filename, 'wb') as binary_file:\n",
    "        bits.tofile(binary_file)\n",
    "\n",
    "\n",
    "def load_from_files(code_filename, binary_filename, text_length):\n",
    "    with open(code_filename) as code_file:\n",
    "        code_data = code_file.read()\n",
    "    split_codes = code_data.split(\";\")\n",
    "    codes = {split_codes[i]: split_codes[i + 1] for i in range(0, len(split_codes) - 1, 2)}\n",
    "\n",
    "    bits = bitarray.bitarray()\n",
    "    with open(binary_filename, 'rb') as binary_file:\n",
    "        bits.fromfile(binary_file)\n",
    "    loaded_text = bits.to01()[:text_length]\n",
    "\n",
    "    return loaded_text, codes\n",
    "\n",
    "\n",
    "def compute_compression_ratio(text, codebook):\n",
    "    uncompressed_size = len(text) * 8\n",
    "    compressed_size = sum(len(codebook[char]) for char in text)\n",
    "    return uncompressed_size / compressed_size\n",
    "\n",
    "\n",
    "def compute_average_length(codes, text_length, frequency_dict):\n",
    "    average_length = np.sum([(freq / text_length) * len(codes[char]) for char, freq in frequency_dict])\n",
    "    return average_length\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c057442f-312d-4a57-8a33-fa4729008660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the original text equal to the decoded text? True\n",
      "Is the original text equal to the decoded text (from file)? True\n",
      "Compression ratio: 1.8565725743118144\n",
      "Average length of code words: 4.3090155002237935\n",
      "Entropy: 4.2803962467015655\n",
      "Coding efficiency: 0.9933582848516693\n"
     ]
    }
   ],
   "source": [
    "input_text = open(\"norm_wiki_sample.txt\").read()\n",
    "codebook = build_tree(input_text)\n",
    "encoded_text = encode_text(input_text, codebook)\n",
    "decoded_text = decode_text(encoded_text, codebook)\n",
    "\n",
    "print(\"Is the original text equal to the decoded text?\", input_text == decoded_text)\n",
    "\n",
    "save_to_files(\"codebook.txt\", codebook, \"encoded.bin\", encoded_text)\n",
    "\n",
    "text_length = len(encoded_text)\n",
    "loaded_encoded_text, loaded_codebook = load_from_files(\"codebook.txt\", \"encoded.bin\", text_length)\n",
    "decoded_text_from_file = decode_text(loaded_encoded_text, loaded_codebook)\n",
    "\n",
    "print(\"Is the original text equal to the decoded text (from file)?\", input_text == decoded_text_from_file)\n",
    "print(\"Compression ratio:\", compute_compression_ratio(input_text, codebook))\n",
    "\n",
    "frequency_dict = calculate_frequency(input_text, alphabet)\n",
    "average_code_length = compute_average_length(codebook, len(input_text), frequency_dict)\n",
    "print(\"Average length of code words:\", average_code_length)\n",
    "\n",
    "text_entropy = np.sum([(freq / len(input_text)) * np.log2(freq / len(input_text)) for _, freq in frequency_dict]) * -1\n",
    "print(\"Entropy:\", text_entropy)\n",
    "print(\"Coding efficiency:\", text_entropy / average_code_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06195cf-21a4-4579-aea3-fb5042e1fdea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
